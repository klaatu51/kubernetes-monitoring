apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    component: server
  creationTimestamp: null
  name: prometheus-server-conf
  namespace: monitoring
data:
  alerts: |
    "groups":
    - "name": "kubernetes-apps"
      "rules":
      - "alert": "KubePodCrashLooping"
        "annotations":
          "message": "Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf \"%.2f\" $value }} times / 5 minutes."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping"
        "expr": |
          rate(kube_pod_container_status_restarts_total{job="kubernetes-service-endpoints"}[15m]) * 60 * 5 > 0
        "for": "1h"
        "labels":
          "severity": "critical"
      - "alert": "KubePodNotReady"
        "annotations":
          "message": "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready"
        "expr": |
          sum by (namespace, pod) (kube_pod_status_phase{job="kubernetes-service-endpoints", phase=~"Pending|Unknown"}) > 0
        "for": "1h"
        "labels":
          "severity": "critical"
      - "alert": "KubeDeploymentGenerationMismatch"
        "annotations":
          "message": "Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch"
        "expr": |
          kube_deployment_status_observed_generation{job="kubernetes-service-endpoints"}
            !=
          kube_deployment_metadata_generation{job="kubernetes-service-endpoints"}
        "for": "15m"
        "labels":
          "severity": "critical"
      - "alert": "KubeDeploymentReplicasMismatch"
        "annotations":
          "message": "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than an hour."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch"
        "expr": |
          kube_deployment_spec_replicas{job="kubernetes-service-endpoints"}
            !=
          kube_deployment_status_replicas_available{job="kubernetes-service-endpoints"}
        "for": "1h"
        "labels":
          "severity": "critical"
      - "alert": "KubeStatefulSetReplicasMismatch"
        "annotations":
          "message": "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"
        "expr": |
          kube_statefulset_status_replicas_ready{job="kubernetes-service-endpoints"}
            !=
          kube_statefulset_status_replicas{job="kubernetes-service-endpoints"}
        "for": "15m"
        "labels":
          "severity": "critical"
      - "alert": "KubeStatefulSetGenerationMismatch"
        "annotations":
          "message": "StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch"
        "expr": |
          kube_statefulset_status_observed_generation{job="kubernetes-service-endpoints"}
            !=
          kube_statefulset_metadata_generation{job="kubernetes-service-endpoints"}
        "for": "15m"
        "labels":
          "severity": "critical"
      - "alert": "KubeStatefulSetUpdateNotRolledOut"
        "annotations":
          "message": "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout"
        "expr": |
          max without (revision) (
            kube_statefulset_status_current_revision{job="kubernetes-service-endpoints"}
              unless
            kube_statefulset_status_update_revision{job="kubernetes-service-endpoints"}
          )
            *
          (
            kube_statefulset_replicas{job="kubernetes-service-endpoints"}
              !=
            kube_statefulset_status_replicas_updated{job="kubernetes-service-endpoints"}
          )
        "for": "15m"
        "labels":
          "severity": "critical"
      - "alert": "KubeDaemonSetRolloutStuck"
        "annotations":
          "message": "Only {{ $value }}% of the desired Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are scheduled and ready."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck"
        "expr": |
          kube_daemonset_status_number_ready{job="kubernetes-service-endpoints"}
            /
          kube_daemonset_status_desired_number_scheduled{job="kubernetes-service-endpoints"} * 100 < 100
        "for": "15m"
        "labels":
          "severity": "critical"
      - "alert": "KubeDaemonSetNotScheduled"
        "annotations":
          "message": "{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled"
        "expr": |
          kube_daemonset_status_desired_number_scheduled{job="kubernetes-service-endpoints"}
            -
          kube_daemonset_status_current_number_scheduled{job="kubernetes-service-endpoints"} > 0
        "for": "10m"
        "labels":
          "severity": "warning"
      - "alert": "KubeDaemonSetMisScheduled"
        "annotations":
          "message": "{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled"
        "expr": |
          kube_daemonset_status_number_misscheduled{job="kubernetes-service-endpoints"} > 0
        "for": "10m"
        "labels":
          "severity": "warning"
      - "alert": "KubeCronJobRunning"
        "annotations":
          "message": "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1h to complete."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecronjobrunning"
        "expr": |
          time() - kube_cronjob_next_schedule_time{job="kubernetes-service-endpoints"} > 3600
        "for": "1h"
        "labels":
          "severity": "warning"
      - "alert": "KubeJobCompletion"
        "annotations":
          "message": "Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than one hour to complete."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion"
        "expr": |
          kube_job_spec_completions{job="kubernetes-service-endpoints"} - kube_job_status_succeeded{job="kubernetes-service-endpoints"}  > 0
        "for": "1h"
        "labels":
          "severity": "warning"
      - "alert": "KubeJobFailed"
        "annotations":
          "message": "Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed"
        "expr": |
          kube_job_status_failed{job="kubernetes-service-endpoints"}  > 0
        "for": "1h"
        "labels":
          "severity": "warning"
    - "name": "kubernetes-resources"
      "rules":
      - "alert": "KubeCPUOvercommit"
        "annotations":
          "message": "Cluster has overcommitted CPU resource requests for Pods and cannot tolerate node failure."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit"
        "expr": |
          sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)
            /
          sum(node:node_num_cpu:sum)
            >
          (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)
        "for": "5m"
        "labels":
          "severity": "warning"
      - "alert": "KubeMemOvercommit"
        "annotations":
          "message": "Cluster has overcommitted memory resource requests for Pods and cannot tolerate node failure."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit"
        "expr": |
          sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)
            /
          sum(node_memory_MemTotal_bytes)
            >
          (count(node:node_num_cpu:sum)-1)
            /
          count(node:node_num_cpu:sum)
        "for": "5m"
        "labels":
          "severity": "warning"
      - "alert": "KubeCPUOvercommit"
        "annotations":
          "message": "Cluster has overcommitted CPU resource requests for Namespaces."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit"
        "expr": |
          sum(kube_resourcequota{job="kubernetes-service-endpoints", type="hard", resource="cpu"})
            /
          sum(node:node_num_cpu:sum)
            > 1.5
        "for": "5m"
        "labels":
          "severity": "warning"
      - "alert": "KubeMemOvercommit"
        "annotations":
          "message": "Cluster has overcommitted memory resource requests for Namespaces."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit"
        "expr": |
          sum(kube_resourcequota{job="kubernetes-service-endpoints", type="hard", resource="memory"})
            /
          sum(node_memory_MemTotal_bytes{job="kubernetes-service-endpoints"})
            > 1.5
        "for": "5m"
        "labels":
          "severity": "warning"
      - "alert": "KubeQuotaExceeded"
        "annotations":
          "message": "Namespace {{ $labels.namespace }} is using {{ printf \"%0.0f\" $value }}% of its {{ $labels.resource }} quota."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded"
        "expr": |
          100 * kube_resourcequota{job="kubernetes-service-endpoints", type="used"}
            / ignoring(instance, job, type)
          (kube_resourcequota{job="kubernetes-service-endpoints", type="hard"} > 0)
            > 90
        "for": "15m"
        "labels":
          "severity": "warning"
      - "alert": "CPUThrottlingHigh"
        "annotations":
          "message": "{{ printf \"%0.0f\" $value }}% throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container_name }} in pod {{ $labels.pod_name }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh"
        "expr": |
          100 * sum(increase(container_cpu_cfs_throttled_periods_total{container_name!="", }[5m])) by (container_name, pod_name, namespace)
            /
          sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container_name, pod_name, namespace)
            > 25 
        "for": "15m"
        "labels":
          "severity": "warning"
    - "name": "kubernetes-storage"
      "rules":
      - "alert": "KubePersistentVolumeUsageCritical"
        "annotations":
          "message": "The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is only {{ printf \"%0.2f\" $value }}% free."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeusagecritical"
        "expr": |
          100 * kubelet_volume_stats_available_bytes{job="kubernetes-nodes"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubernetes-nodes"}
            < 3
        "for": "1m"
        "labels":
          "severity": "critical"
      - "alert": "KubePersistentVolumeFullInFourDays"
        "annotations":
          "message": "Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is expected to fill up within four days. Currently {{ printf \"%0.2f\" $value }}% is available."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefullinfourdays"
        "expr": |
          100 * (
            kubelet_volume_stats_available_bytes{job="kubernetes-nodes"}
              /
            kubelet_volume_stats_capacity_bytes{job="kubernetes-nodes"}
          ) < 15
          and
          predict_linear(kubelet_volume_stats_available_bytes{job="kubernetes-nodes"}[6h], 4 * 24 * 3600) < 0
        "for": "5m"
        "labels":
          "severity": "critical"
      - "alert": "KubePersistentVolumeErrors"
        "annotations":
          "message": "The persistent volume {{ $labels.persistentvolume }} has status {{ $labels.phase }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors"
        "expr": |
          kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kubernetes-service-endpoints"} > 0
        "for": "5m"
        "labels":
          "severity": "critical"
    - "name": "kubernetes-system"
      "rules":
      - "alert": "KubeNodeNotReady"
        "annotations":
          "message": "{{ $labels.node }} has been unready for more than an hour."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready"
        "expr": |
          kube_node_status_condition{job="kubernetes-service-endpoints",condition="Ready",status="true"} == 0
        "for": "1h"
        "labels":
          "severity": "warning"
      - "alert": "KubeVersionMismatch"
        "annotations":
          "message": "There are {{ $value }} different semantic versions of Kubernetes components running."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch"
        "expr": |
          count(count by (gitVersion) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"gitVersion","$1","gitVersion","(v[0-9]*.[0-9]*.[0-9]*).*"))) > 1
        "for": "1h"
        "labels":
          "severity": "warning"
      - "alert": "KubeClientErrors"
        "annotations":
          "message": "Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ printf \"%0.0f\" $value }}% errors.'"
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors"
        "expr": |
          (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job)
            /
          sum(rate(rest_client_requests_total[5m])) by (instance, job))
          * 100 > 1
        "for": "15m"
        "labels":
          "severity": "warning"
      - "alert": "KubeClientErrors"
        "annotations":
          "message": "Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ printf \"%0.0f\" $value }} errors / second."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors"
        "expr": |
          sum(rate(ksm_scrape_error_total{job="kubernetes-service-endpoints"}[5m])) by (instance, job) > 0.1
        "for": "15m"
        "labels":
          "severity": "warning"
      - "alert": "KubeletTooManyPods"
        "annotations":
          "message": "Kubelet {{ $labels.instance }} is running {{ $value }} Pods, close to the limit of 110."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods"
        "expr": |
          kubelet_running_pod_count{job="kubernetes-nodes"} > 110 * 0.9
        "for": "15m"
        "labels":
          "severity": "warning"
      - "alert": "KubeAPILatencyHigh"
        "annotations":
          "message": "The API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh"
        "expr": |
          cluster_quantile:apiserver_request_latencies:histogram_quantile{job="kube-apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 1
        "for": "10m"
        "labels":
          "severity": "warning"
      - "alert": "KubeAPILatencyHigh"
        "annotations":
          "message": "The API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh"
        "expr": |
          cluster_quantile:apiserver_request_latencies:histogram_quantile{job="kube-apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 4
        "for": "10m"
        "labels":
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations":
          "message": "API server is returning errors for {{ $value }}% of requests."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="kube-apiserver",code=~"^(?:5..)$"}[5m]))
            /
          sum(rate(apiserver_request_count{job="kube-apiserver"}[5m])) * 100 > 3
        "for": "10m"
        "labels":
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations":
          "message": "API server is returning errors for {{ $value }}% of requests."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="kube-apiserver",code=~"^(?:5..)$"}[5m]))
            /
          sum(rate(apiserver_request_count{job="kube-apiserver"}[5m])) * 100 > 1
        "for": "10m"
        "labels":
          "severity": "warning"
      - "alert": "KubeAPIErrorsHigh"
        "annotations":
          "message": "API server is returning errors for {{ $value }}% of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="kube-apiserver",code=~"^(?:5..)$"}[5m])) by (resource,subresource,verb)
            /
          sum(rate(apiserver_request_count{job="kube-apiserver"}[5m])) by (resource,subresource,verb) * 100 > 10
        "for": "10m"
        "labels":
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations":
          "message": "API server is returning errors for {{ $value }}% of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource }}."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="kube-apiserver",code=~"^(?:5..)$"}[5m])) by (resource,subresource,verb)
            /
          sum(rate(apiserver_request_count{job="kube-apiserver"}[5m])) by (resource,subresource,verb) * 100 > 5
        "for": "10m"
        "labels":
          "severity": "warning"
      - "alert": "KubeClientCertificateExpiration"
        "annotations":
          "message": "A client certificate used to authenticate to the apiserver is expiring in less than 7.0 days."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration"
        "expr": |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kube-apiserver"}[5m]))) < 604800
        "labels":
          "severity": "warning"
      - "alert": "KubeClientCertificateExpiration"
        "annotations":
          "message": "A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours."
          "runbook_url": "https://github.com/kubernetes-default/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration"
        "expr": |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kube-apiserver"}[5m]))) < 86400
        "labels":
          "severity": "critical"
  prometheus.yml: |
    global:
      scrape_interval: 10s
      scrape_timeout: 10s
      evaluation_interval: 10s
      external_labels:
        cluster: minikube
    rule_files:
    - /etc/prometheus/rules
    - /etc/prometheus/alerts
    scrape_configs:
    - job_name: prometheus
      static_configs:
      - targets:
        - localhost:9090
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
    - job_name: kubernetes-service-endpoints-slow
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
      scrape_interval: 5m
      scrape_timeout: 30s
    - honor_labels: true
      job_name: prometheus-pushgateway
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - action: keep
        regex: pushgateway
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
    - job_name: kubernetes-services
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: kubernetes_pod_name
    - job_name: kubernetes-pods-slow
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: kubernetes_pod_name
      scrape_interval: 5m
      scrape_timeout: 30s
    alerting:
      alertmanagers:
      - kubernetes_sd_configs:
          - role: pod
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace]
          regex: default
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_app]
          regex: prometheus
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_component]
          regex: alertmanager
          action: keep
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_probe]
          regex: .*
          action: keep
        - source_labels: [__meta_kubernetes_pod_container_port_number]
          regex:
          action: drop
  rules: |
    "groups":
    - "name": "k8s.rules"
      "rules":
      - "expr": |
          sum(rate(container_cpu_usage_seconds_total{job="kubernetes-nodes-cadvisor", image!="", container_name!=""}[5m])) by (namespace)
        "record": "namespace:container_cpu_usage_seconds_total:sum_rate"
      - "expr": |
          sum(container_memory_usage_bytes{job="kubernetes-nodes-cadvisor", image!="", container_name!=""}) by (namespace)
        "record": "namespace:container_memory_usage_bytes:sum"
      - "expr": |
          sum by (namespace, pod_name, container_name) (
            rate(container_cpu_usage_seconds_total{job="kubernetes-nodes-cadvisor", image!="", container_name!=""}[5m])
          )
        "record": "namespace_pod_name_container_name:container_cpu_usage_seconds_total:sum_rate"
      - "expr": |
          sum by(namespace) (
              kube_pod_container_resource_requests_memory_bytes{job="kubernetes-service-endpoints"}
            * on (endpoint, instance, job, namespace, pod, service)
              group_left(phase) (kube_pod_status_phase{phase=~"^(Pending|Running)$"} == 1)
          )
        "record": "namespace_name:kube_pod_container_resource_requests_memory_bytes:sum"
      - "expr": |
          sum by (namespace) (
              kube_pod_container_resource_requests_cpu_cores{job="kubernetes-service-endpoints"}
            * on (endpoint, instance, job, namespace, pod, service)
              group_left(phase) (kube_pod_status_phase{phase=~"^(Pending|Running)$"} == 1)
          )
        "record": "namespace_name:kube_pod_container_resource_requests_cpu_cores:sum"
      - "expr": |
          sum(
            label_replace(
              label_replace(
                kube_pod_owner{job="kubernetes-service-endpoints", owner_kind="ReplicaSet"},
                "replicaset", "$1", "owner_name", "(.*)"
              ) * on(replicaset, namespace) group_left(owner_name) kube_replicaset_owner{job="kubernetes-service-endpoints"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels":
          "workload_type": "deployment"
        "record": "mixin_pod_workload"
      - "expr": |
          sum(
            label_replace(
              kube_pod_owner{job="kubernetes-service-endpoints", owner_kind="DaemonSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels":
          "workload_type": "daemonset"
        "record": "mixin_pod_workload"
      - "expr": |
          sum(
            label_replace(
              kube_pod_owner{job="kubernetes-service-endpoints", owner_kind="StatefulSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels":
          "workload_type": "statefulset"
        "record": "mixin_pod_workload"
    - "name": "kube-scheduler.rules"
      "rules":
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
    - "name": "kube-apiserver.rules"
      "rules":
      - "expr": |
          histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="kube-apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.99"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job="kube-apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.9"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job="kube-apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels":
          "quantile": "0.5"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
    - "name": "node.rules"
      "rules":
      - "expr": "sum(min(kube_pod_info) by (node))"
        "record": ":kube_pod_info_node_count:"
      - "expr": |
          max(label_replace(kube_pod_info{job="kubernetes-service-endpoints"}, "pod", "$1", "pod", "(.*)")) by (node, namespace, pod)
        "record": "node_namespace_pod:kube_pod_info:"
      - "expr": |
          count by (node) (sum by (node, cpu) (
            node_cpu_seconds_total{job="kubernetes-service-endpoints"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          ))
        "record": "node:node_num_cpu:sum"
      - "expr": |
          1 - avg(rate(node_cpu_seconds_total{job="kubernetes-service-endpoints",mode="idle"}[1m]))
        "record": ":node_cpu_utilisation:avg1m"
      - "expr": |
          1 - avg by (node) (
            rate(node_cpu_seconds_total{job="kubernetes-service-endpoints",mode="idle"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:)
        "record": "node:node_cpu_utilisation:avg1m"
      - "expr": |
          node:node_cpu_utilisation:avg1m
            *
          node:node_num_cpu:sum
            /
          scalar(sum(node:node_num_cpu:sum))
        "record": "node:cluster_cpu_utilisation:ratio"
      - "expr": |
          sum(node_load1{job="kubernetes-service-endpoints"})
          /
          sum(node:node_num_cpu:sum)
        "record": ":node_cpu_saturation_load1:"
      - "expr": |
          sum by (node) (
            node_load1{job="kubernetes-service-endpoints"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
          /
          node:node_num_cpu:sum
        "record": "node:node_cpu_saturation_load1:"
      - "expr": |
          1 -
          sum(node_memory_MemFree_bytes{job="kubernetes-service-endpoints"} + node_memory_Cached_bytes{job="kubernetes-service-endpoints"} + node_memory_Buffers_bytes{job="kubernetes-service-endpoints"})
          /
          sum(node_memory_MemTotal_bytes{job="kubernetes-service-endpoints"})
        "record": ":node_memory_utilisation:"
      - "expr": |
          sum(node_memory_MemFree_bytes{job="kubernetes-service-endpoints"} + node_memory_Cached_bytes{job="kubernetes-service-endpoints"} + node_memory_Buffers_bytes{job="kubernetes-service-endpoints"})
        "record": ":node_memory_MemFreeCachedBuffers_bytes:sum"
      - "expr": |
          sum(node_memory_MemTotal_bytes{job="kubernetes-service-endpoints"})
        "record": ":node_memory_MemTotal_bytes:sum"
      - "expr": |
          sum by (node) (
            (node_memory_MemFree_bytes{job="kubernetes-service-endpoints"} + node_memory_Cached_bytes{job="kubernetes-service-endpoints"} + node_memory_Buffers_bytes{job="kubernetes-service-endpoints"})
            * on (namespace, pod) group_left(node)
              node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_bytes_available:sum"
      - "expr": |
          sum by (node) (
            node_memory_MemTotal_bytes{job="kubernetes-service-endpoints"}
            * on (namespace, pod) group_left(node)
              node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_bytes_total:sum"
      - "expr": |
          (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
          /
          node:node_memory_bytes_total:sum
        "record": "node:node_memory_utilisation:ratio"
      - "expr": |
          (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
          /
          scalar(sum(node:node_memory_bytes_total:sum))
        "record": "node:cluster_memory_utilisation:ratio"
      - "expr": |
          1e3 * sum(
            (rate(node_vmstat_pgpgin{job="kubernetes-service-endpoints"}[1m])
          + rate(node_vmstat_pgpgout{job="kubernetes-service-endpoints"}[1m]))
          )
        "record": ":node_memory_swap_io_bytes:sum_rate"
      - "expr": |
          1 -
          sum by (node) (
            (node_memory_MemFree_bytes{job="kubernetes-service-endpoints"} + node_memory_Cached_bytes{job="kubernetes-service-endpoints"} + node_memory_Buffers_bytes{job="kubernetes-service-endpoints"})
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
          /
          sum by (node) (
            node_memory_MemTotal_bytes{job="kubernetes-service-endpoints"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_utilisation:"
      - "expr": |
          1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
        "record": "node:node_memory_utilisation_2:"
      - "expr": |
          1e3 * sum by (node) (
            (rate(node_vmstat_pgpgin{job="kubernetes-service-endpoints"}[1m])
          + rate(node_vmstat_pgpgout{job="kubernetes-service-endpoints"}[1m]))
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_swap_io_bytes:sum_rate"
      - "expr": |
          avg(irate(node_disk_io_time_seconds_total{job="kubernetes-service-endpoints",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
        "record": ":node_disk_utilisation:avg_irate"
      - "expr": |
          avg by (node) (
            irate(node_disk_io_time_seconds_total{job="kubernetes-service-endpoints",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_disk_utilisation:avg_irate"
      - "expr": |
          avg(irate(node_disk_io_time_weighted_seconds_total{job="kubernetes-service-endpoints",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
        "record": ":node_disk_saturation:avg_irate"
      - "expr": |
          avg by (node) (
            irate(node_disk_io_time_weighted_seconds_total{job="kubernetes-service-endpoints",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_disk_saturation:avg_irate"
      - "expr": |
          max by (instance, namespace, pod, device) ((node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"}
          - node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
          / node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
        "record": "node:node_filesystem_usage:"
      - "expr": |
          max by (instance, namespace, pod, device) (node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"} / node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
        "record": "node:node_filesystem_avail:"
      - "expr": |
          sum(irate(node_network_receive_bytes_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m])) +
          sum(irate(node_network_transmit_bytes_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]))
        "record": ":node_net_utilisation:sum_irate"
      - "expr": |
          sum by (node) (
            (irate(node_network_receive_bytes_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]) +
            irate(node_network_transmit_bytes_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]))
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_net_utilisation:sum_irate"
      - "expr": |
          sum(irate(node_network_receive_drop_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m])) +
          sum(irate(node_network_transmit_drop_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]))
        "record": ":node_net_saturation:sum_irate"
      - "expr": |
          sum by (node) (
            (irate(node_network_receive_drop_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]) +
            irate(node_network_transmit_drop_total{job="kubernetes-service-endpoints",device!~"veth.+"}[1m]))
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_net_saturation:sum_irate"
      - "expr": |
          max(
            max(
              kube_pod_info{job="kubernetes-service-endpoints", host_ip!=""}
            ) by (node, host_ip)
            * on (host_ip) group_right (node)
            label_replace(
              (max(node_filesystem_files{job="kubernetes-service-endpoints", mountpoint="/"}) by (instance)), "host_ip", "$1", "instance", "(.*):.*"
            )
          ) by (node)
        "record": "node:node_inodes_total:"
      - "expr": |
          max(
            max(
              kube_pod_info{job="kubernetes-service-endpoints", host_ip!=""}
            ) by (node, host_ip)
            * on (host_ip) group_right (node)
            label_replace(
              (max(node_filesystem_files_free{job="kubernetes-service-endpoints", mountpoint="/"}) by (instance)), "host_ip", "$1", "instance", "(.*):.*"
            )
          ) by (node)
        "record": "node:node_inodes_free:"
